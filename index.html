<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Enhancing Embodied Object Detection through Language-Image Pre-training and Implicit Object Memory.">
  <meta name="keywords" content="Object Detection, Language-Image Pre-training, Implicit Object Memory">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Enhancing Embodied Object Detection through Language-Image Pre-training and Implicit Object Memory.</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>

<!-- Remove navbar -->
<!--   <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div> -->

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Enhancing Embodied Object Detection through Language-Image Pre-training and Implicit Object Memory</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=kBdGmzAAAAAJ&hl=en">Nicolas Harvey Chapman</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ferasdayoub.com/">Feras Dayoub</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.qut.edu.au/about/our-people/academic-profiles/will.browne">Will Browne</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.qut.edu.au/about/our-people/academic-profiles/c.lehnert">Chris Lehnert</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Queensland University of Technology,</span>
            <span class="author-block"><sup>2</sup>University of Adelaide</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.03721"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.03721"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/nhcha6"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
<!--               <!-- Video Link. -->
<!--               <span class="link-block"> -->
<!--                 <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA" -->
<!--                    class="external-link button is-normal is-rounded is-dark"> -->
<!--                   <span class="icon"> -->
<!--                       <i class="fab fa-youtube"></i> -->
<!--                   </span> -->
<!--                   <span>Video</span> -->
<!--                 </a> -->
<!--               </span> -->
<!--               <!-- Dataset Link. -->
<!--               <span class="link-block"> -->
<!--                 <a href="https://github.com/google/nerfies/releases/tag/0.1" -->
<!--                    class="external-link button is-normal is-rounded is-dark"> -->
<!--                   <span class="icon"> -->
<!--                       <i class="far fa-images"></i> -->
<!--                   </span> -->
<!--                   <span>Data</span> -->
<!--                   </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
  
<section class="hero teaser">
  <div class="container is-max-desktop">
<!--     <h2 class="title is-3">Video</h2> -->
        <h2 class="subtitle has-text-centered">
        We study the task of <b>embodied object detection</b>, where a robot must detect objects in a multi-modal data stream collected from indoor scenes.
      </h2>
      <h2 class="subtitle has-text-centered">
        Our solution enhances embodied object detection performance using <b>language-image pre-training</b> and a <b>novel external memory</b>.
      </h2>
    <div class="hero-body">
      <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./media/entire_video.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          
          <p>
            Deep-learning and large scale language-image training have produced image object detectors that generalise well to diverse environments and semantic classes. 
            However, single-image object detectors trained on internet data are not optimally tailored for the embodied conditions inherent in robotics. 
            Instead, robots must detect objects from complex multi-modal data streams involving depth, localisation and temporal correlation, a task termed embodied object detection.
          </p>
          <p>
            Paradigms such as Video Object Detection (VOD) and Semantic Mapping have been proposed to leverage such embodied data streams, but existing work fails to enhance performance using language-image training. 
            In response, we investigate how an image object detector pre-trained using language-image data can be extended to perform embodied object detection.
            We propose a novel implicit object memory that uses projective geometry to aggregate the features of detected objects across long temporal horizons. 
            The spatial and temporal information accumulated in memory is then used to enhance the image features of the base detector. 
          </p>
          <p>
           When tested on embodied data streams sampled from diverse indoor scenes, our approach improves the base object detector by 3.09 mAP, outperforming alternative external memories designed for VOD and Semantic Mapping. 
           Our method also shows a significant improvement of 16.90 mAP relative to baselines that perform embodied object detection without first training on language-image data, and is robust to sensor noise and domain shift experienced in real-world deployment.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{chapman2024enhancing,
  title={Enhancing Embodied Object Detection through Language-Image Pre-training and Implicit Object Memory},
  author={Chapman, Nicolas Harvey and Dayoub, Feras and Browne, Will and Lehnert, Chris},
  journal={arXiv preprint arXiv:2402.03721},
  year={2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
        <div class="content has-text-centered">
          Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">here</a>
          </p>
        </div>
    </div>
  </div>
</footer>

</body>
</html>
